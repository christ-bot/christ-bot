{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christ-bot/christ-bot/blob/main/vocabularymatching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f43d95",
      "metadata": {
        "id": "00f43d95"
      },
      "outputs": [],
      "source": [
        "pip install spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4791c5d",
      "metadata": {
        "id": "d4791c5d"
      },
      "outputs": [],
      "source": [
        "pip install thefuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28f46c8-5faf-4604-ad0d-4d2dafc25d2c",
      "metadata": {
        "id": "a28f46c8-5faf-4604-ad0d-4d2dafc25d2c"
      },
      "outputs": [],
      "source": [
        "#import libralies\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "from thefuzz import fuzz, process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a2fb37-a86f-443b-a25f-3b8346f076a9",
      "metadata": {
        "id": "d1a2fb37-a86f-443b-a25f-3b8346f076a9"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d9a97a-c454-4633-871f-70bfdb56527c",
      "metadata": {
        "id": "37d9a97a-c454-4633-871f-70bfdb56527c"
      },
      "outputs": [],
      "source": [
        "# set pandas to display all rows\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dacc1dd6-7d51-4a87-a6bc-b2846326d330",
      "metadata": {
        "id": "dacc1dd6-7d51-4a87-a6bc-b2846326d330"
      },
      "outputs": [],
      "source": [
        "# Matched examples\n",
        "df_matched = pd.read_csv('matched_data.csv')\n",
        "df_matched"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "558ac67a-c081-456e-b865-2e7675006875",
      "metadata": {
        "tags": [],
        "id": "558ac67a-c081-456e-b865-2e7675006875"
      },
      "source": [
        "# Fuzzy string matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1e51d9-a48d-49ae-a3c8-1ddc778880fd",
      "metadata": {
        "id": "4e1e51d9-a48d-49ae-a3c8-1ddc778880fd"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = LancasterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92d8c34-40b3-4ecc-a768-eb4812c5e59f",
      "metadata": {
        "scrolled": true,
        "id": "f92d8c34-40b3-4ecc-a768-eb4812c5e59f"
      },
      "outputs": [],
      "source": [
        "def root_words(string):\n",
        "    wrds = nltk.word_tokenize(string)\n",
        "    roots = [lemmatizer.lemmatize(word.lower()) for word in wrds]\n",
        "    #roots = [stemmer.stem(word.lower()) for word in wrds]\n",
        "    return roots\n",
        "root_words('computer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd35cbdd-c744-4fde-8326-302008945bde",
      "metadata": {
        "id": "cd35cbdd-c744-4fde-8326-302008945bde"
      },
      "outputs": [],
      "source": [
        "def get_synonyms(string):\n",
        "    synonyms = []\n",
        "    for syn in wordnet.synsets(string):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "    res = []\n",
        "    for syn in synonyms:\n",
        "        if '_' in syn:\n",
        "            res.extend(syn.split('_'))\n",
        "            #res.append(' '.join(syn.split('_')))\n",
        "        else:\n",
        "            res.append(syn)\n",
        "    return res\n",
        "get_synonyms('computer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328350e2-17b6-49ce-8a46-3d41ea643b00",
      "metadata": {
        "id": "328350e2-17b6-49ce-8a46-3d41ea643b00"
      },
      "outputs": [],
      "source": [
        "def get_match(source_1, source_2):\n",
        "    def get_ratios(i, j):\n",
        "        print(f\"'{i}' vs '{j}'\")\n",
        "\n",
        "        ratio = fuzz.ratio(i, j)\n",
        "        print(f\"Ratio : {ratio}\")\n",
        "\n",
        "        partial_ratio = fuzz.partial_ratio(root_words(i)[0], j)\n",
        "        print(f\"Partial Ratio : {partial_ratio}\")\n",
        "\n",
        "        token_sort_ratio = fuzz.token_sort_ratio(i, j)\n",
        "        print(f\"Token sort Ratio : {token_sort_ratio}\")\n",
        "\n",
        "        token_set_ratio = fuzz.token_set_ratio(i, j)\n",
        "        print(f\"Token set Ratio : {token_set_ratio}\")\n",
        "        print()\n",
        "\n",
        "        return partial_ratio, token_set_ratio\n",
        "\n",
        "    for i in source_2:\n",
        "        i = i.strip()\n",
        "        synonyms = get_synonyms(i) if ' ' not in i else None\n",
        "        all_synonyms = ''\n",
        "        if synonyms:\n",
        "            synonym_str = ' '.join(synonyms)\n",
        "            all_synonyms = i + ' ' + synonym_str\n",
        "\n",
        "        for j in source_1:\n",
        "            token_set_ratio = get_ratios(i, j)[1]\n",
        "            if token_set_ratio == 100:\n",
        "                break\n",
        "            if len(all_synonyms) > 0:\n",
        "                partial_ratio = get_ratios(all_synonyms, j)[0]\n",
        "                if partial_ratio > 80:\n",
        "                    break\n",
        "            else:\n",
        "                continue\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdba5053-c6b7-44ac-afdf-b030cbf77694",
      "metadata": {
        "id": "cdba5053-c6b7-44ac-afdf-b030cbf77694"
      },
      "outputs": [],
      "source": [
        "src_1 = df_matched.source_1\n",
        "src_2 = df_matched.source_2\n",
        "get_match(src_1, src_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c7d4e25-ab08-42a6-9420-7e9dabbc96b1",
      "metadata": {
        "id": "7c7d4e25-ab08-42a6-9420-7e9dabbc96b1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "draft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}